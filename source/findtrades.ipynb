{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3235bb4a-cf99-4d8a-9ff9-30e8352b5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import concurrent.futures\n",
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import process.auxiliares as aux\n",
    "\n",
    "\n",
    "###PARÂMETROS\n",
    "\n",
    "#Configurando o log no terminal\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Definir o nível de log\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Formato de saída\n",
    "    force=True\n",
    ")\n",
    "\n",
    "#Configurando pastas\n",
    "path_Data = '../data'\n",
    "path_Data_STG = path_Data + '/STG'\n",
    "path_Data_STG_Controle = path_Data_STG + '/controle/listacodnegs.csv'\n",
    "path_Data_STG_Acoes_Intraday = path_Data_STG + '/acoes_intraday/'\n",
    "path_Data_STG_Acoes_Diario = path_Data_STG + '/acoes_diario/'\n",
    "\n",
    "path_Data_ODS = path_Data + '/ODS'\n",
    "path_Data_ODS_Acoes_Estrategia001_Diario = path_Data_ODS + '/acoes_diario_estrategia001'\n",
    "path_Data_ODS_Acoes_Estrategia002_Diario = path_Data_ODS + '/acoes_diario_estrategia002'\n",
    "\n",
    "path_Data_DM = path_Data + '/DM'\n",
    "path_Data_DM_Acoes_Estrategia001_Diario_Consolidado = path_Data_DM + '/acoes_diario_estrategia001_consolidado.csv'\n",
    "path_Data_DM_Acoes_Estrategia002_Diario_Consolidado = path_Data_DM + '/acoes_diario_estrategia002_consolidado.csv'\n",
    "\n",
    "#path_Data_DM_Acoes_Estrategia001001_Diario_Detalhe = path_Data_DM + '/estrategia001_diario_detalhe.csv'\n",
    "\n",
    "\n",
    "#Maximas threads concorrentes\n",
    "max_threads = 10\n",
    "acoes = []\n",
    "dados_acoes = []    \n",
    "\n",
    "def limpar_pasta(caminho_pasta):    \n",
    "    if os.path.exists(caminho_pasta):        \n",
    "        for arquivo in os.listdir(caminho_pasta):\n",
    "            caminho_arquivo = os.path.join(caminho_pasta, arquivo)            \n",
    "            \n",
    "            if os.path.isfile(caminho_arquivo) or os.path.islink(caminho_arquivo):\n",
    "                os.unlink(caminho_arquivo)  \n",
    "            elif os.path.isdir(caminho_arquivo):\n",
    "                shutil.rmtree(caminho_arquivo)          \n",
    "    else:\n",
    "        logging.error(f\"A pasta '{caminho_pasta}' não existe.\")        \n",
    "\n",
    "# Função para criar pastas se não existirem\n",
    "def criar_pasta(caminho):\n",
    "    if not os.path.exists(caminho):\n",
    "        os.makedirs(caminho)\n",
    "        logging.info(f\"Pasta '{caminho}' criada.\")        \n",
    "    else:\n",
    "        limpar_pasta(caminho)\n",
    "        logging.info(f\"Conteúdo da pasta '{caminho}' apagado.\")\n",
    "\n",
    "def baixar_dados_acao(ticker, path_dados, interval):   \n",
    "    \n",
    "    path_file = path_dados + '/' + ticker.upper() + '.csv'\n",
    "    \n",
    "    acao = yf.Ticker(ticker)\n",
    "    dados = acao.history(period='2y', interval=interval)  \n",
    "    \n",
    "    dados['CODNEG'] = ticker\n",
    "    \n",
    "    if len(dados) > 1:\n",
    "        dados.to_csv(path_file, sep=';', decimal=',')    \n",
    "    \n",
    "    logging.info(f\"{interval} - Dados de {ticker} finalizados.\")    \n",
    "\n",
    "\n",
    "#********************************************************************************************************\n",
    "# ESTRATEGIA 001 - INICIO\n",
    "#********************************************************************************************************\n",
    "def processar_ODS_Estrategia001(path_arquivo, variacao, valor_investido):   \n",
    "    \n",
    "    df_dados = aux.read_Dataframe_csv(path_arquivo)\n",
    "    df_dados['Date'] = pd.to_datetime(df_dados['Date'])\n",
    "    df_dados.sort_values(by='Date', inplace=True)\n",
    "    df_dados['Last Close'] = df_dados['Close'].shift(1)\n",
    "    \n",
    "    df_dados['Var da Minima %'] = ((df_dados['Low'] / df_dados['Last Close']) - 1) * 100\n",
    "    df_dados['Var Fech %'] = ((df_dados['Close'] / df_dados['Last Close']) - 1) * 100\n",
    "    df_dados['Lucro/Prejuizo %'] = np.where(df_dados['Var da Minima %'] <= variacao, df_dados['Var Fech %'] - variacao, 0)\n",
    "    df_dados['Valor de Entrada'] = np.where(df_dados['Var da Minima %'] <= variacao, df_dados['Last Close']*(1+(variacao/100)), 0)    \n",
    "    df_dados['L/P Valor'] = valor_investido * (df_dados['Lucro/Prejuizo %']/100)\n",
    "    df_dados['Valor de Entrada'] = np.where(df_dados['Var da Minima %'] <= variacao, df_dados['Last Close']*(1+(variacao/100)), 0)\n",
    "\n",
    "    arquivo_salvar = path_Data_ODS_Acoes_Estrategia001_Diario + '/' + os.path.basename(path_arquivo)\n",
    "\n",
    "    aux.write_DataFrame_csv(df_dados, arquivo_salvar)   \n",
    "\n",
    "    #soma periodos específicos\n",
    "    df_dados_periodo = df_dados.copy()\n",
    "    \n",
    "    df_dados100 = df_dados_periodo.tail(100)    \n",
    "    soma_lp100 = df_dados100['L/P Valor'].sum()    \n",
    "    qtde_trades_lp100_total = df_dados100[df_dados100['L/P Valor'] != 0]['L/P Valor'].count()    \n",
    "    qtde_trades_lp100_positivos = (df_dados100['L/P Valor'] > 0).sum()\n",
    "    qtde_trades_lp100_negativos = (df_dados100['L/P Valor'] < 0).sum()\n",
    "\n",
    "    df_dados50 = df_dados_periodo.tail(50)\n",
    "    soma_lp50 = df_dados50['L/P Valor'].sum()    \n",
    "    qtde_trades_lp50_total = df_dados50[df_dados50['L/P Valor'] != 0]['L/P Valor'].count()\n",
    "    qtde_trades_lp50_positivos = (df_dados50['L/P Valor'] > 0).sum()\n",
    "    qtde_trades_lp50_negativos = (df_dados50['L/P Valor'] < 0).sum()\n",
    "\n",
    "    df_dados20 = df_dados_periodo.tail(20)    \n",
    "    soma_lp20_total = df_dados20['L/P Valor'].sum()\n",
    "    qtde_trades_lp20_total = df_dados20[df_dados20['L/P Valor'] != 0]['L/P Valor'].count()        \n",
    "    qtde_trades_lp20_positivos = (df_dados20['L/P Valor'] > 0).sum()\n",
    "    qtde_trades_lp20_negativos = (df_dados20['L/P Valor'] < 0).sum()\n",
    "\n",
    "    df_dados1 = df_dados_periodo.tail(1)\n",
    "    valor_entrada_nova = float(df_dados1['Close'].iloc[0]*(1+(variacao/100)))\n",
    "    \n",
    "    codneg = df_dados['CODNEG'].unique()[0]\n",
    "    \n",
    "    dados_acoes.append({'CODNEG': codneg,\n",
    "                             'Valor Entrada Nova': valor_entrada_nova,\n",
    "                             'Parametros - Variacao': variacao,                             \n",
    "                             'Lucro/Prejuizo % - Min': df_dados['Lucro/Prejuizo %'].min(),\n",
    "                             'Lucro/Prejuizo % - Max': df_dados['Lucro/Prejuizo %'].max(),\n",
    "                             'Lucro/Prejuizo % - Avg': df_dados['Lucro/Prejuizo %'].mean(),\n",
    "                             'L/P Valor - Min': df_dados['L/P Valor'].min(),\n",
    "                             'L/P Valor - Max': df_dados['L/P Valor'].max(),\n",
    "                             'L/P Valor - Avg': df_dados['L/P Valor'].mean(),\n",
    "                             'L/P Total 20d': soma_lp20_total,                             \n",
    "                             'L/P Count 20d': qtde_trades_lp20_total,\n",
    "                             'L/P Count 20d positivos': qtde_trades_lp20_positivos,\n",
    "                             'L/P Count 20d negativos': qtde_trades_lp20_negativos,\n",
    "                             'L/P Total 50d': soma_lp50,\n",
    "                             'L/P Count 50d': qtde_trades_lp50_total,\n",
    "                             'L/P Count 50d positivos': qtde_trades_lp50_positivos,\n",
    "                             'L/P Count 50d negativos': qtde_trades_lp50_negativos,\n",
    "                             'L/P Total 100d': soma_lp100,\n",
    "                             'L/P Count 100d': qtde_trades_lp100_total,\n",
    "                             'L/P Count 100d positivos': qtde_trades_lp100_positivos,\n",
    "                             'L/P Count 100d negativos': qtde_trades_lp100_negativos,                                                          \n",
    "                        })    \n",
    "    \n",
    "    logging.info(f\"Dados de {os.path.basename(path_arquivo)} finalizados.\")    \n",
    "\n",
    "def processar_ODS_Estrategia001_Main(variacao, valor_investido):\n",
    "\n",
    "    criar_pasta(path_Data_ODS_Acoes_Estrategia001_Diario)\n",
    "\n",
    "    arquivos_Diario = [(os.path.join(path_Data_STG_Acoes_Diario, f)) \n",
    "                for f in os.listdir(path_Data_STG_Acoes_Diario) if os.path.isfile(os.path.join(path_Data_STG_Acoes_Diario, f))]\n",
    "\n",
    "    threads = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        futures = [executor.submit(processar_ODS_Estrategia001, arquivo, variacao, valor_investido) for arquivo in arquivos_Diario]\n",
    "\n",
    "        # Aguardar todas as threads terminarem\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Captura exceções das threads, se houver\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao baixar dados da ação: {e}\")\n",
    "\n",
    "    df_acoes_consolidada = pd.DataFrame(dados_acoes)\n",
    "    \n",
    "    criar_pasta(path_Data_DM)\n",
    "\n",
    "    #Gerar arquivo consolidado\n",
    "    aux.write_DataFrame_csv(df_acoes_consolidada, path_Data_DM_Acoes_Estrategia001_Diario_Consolidado)   \n",
    "\n",
    "    logging.info(f\"Processamento finalizados.\")    \n",
    "#********************************************************************************************************\n",
    "# ESTRATEGIA 001 - FIM\n",
    "#********************************************************************************************************    \n",
    "\n",
    "#********************************************************************************************************\n",
    "# ESTRATEGIA 002 - INICIO\n",
    "#********************************************************************************************************\n",
    "def processar_ODS_Estrategia002(path_arquivo):\n",
    "    \n",
    "    df_dados = aux.read_Dataframe_csv(path_arquivo)\n",
    "\n",
    "    #Salvar Detalhe    \n",
    "    df_dados['Date'] = pd.to_datetime(df_dados['Date'])\n",
    "    df_dados.sort_values(by='Date', inplace=True)\n",
    "\n",
    "    df_dados['WeekDay'] = df_dados['Date'].dt.strftime(\"%A\")\n",
    "\n",
    "    df_dados = df_dados[df_dados['WeekDay'].isin(['Friday', 'Monday', 'Thursday', 'Wednesday'])]\n",
    "    df_dados.reset_index(inplace=True)\n",
    "\n",
    "    indices_para_remover = []\n",
    "    for i in range(1, len(df_dados) - 1):\n",
    "        dia_atual = df_dados['WeekDay'].iloc[i]\n",
    "        dia_anterior = df_dados['WeekDay'].iloc[i - 1]    \n",
    "        dia_anterior_2 = df_dados['WeekDay'].iloc[i - 2]    \n",
    "        dia_anterior_3 = df_dados['WeekDay'].iloc[i - 3]    \n",
    "        \n",
    "        if dia_atual == 'Monday' and dia_anterior == 'Friday' and dia_anterior_2 == 'Thursday' and dia_anterior_3 == 'Wednesday':\n",
    "            df_dados.at[i, 'High Friday'] = df_dados['High'].iloc[i-1]\n",
    "            df_dados.at[i, 'Low Friday'] = df_dados['Low'].iloc[i-1]\n",
    "            df_dados.at[i, 'Close Thursday'] = df_dados['Close'].iloc[i-2]\n",
    "            df_dados.at[i, 'Close Wednesday'] = df_dados['Close'].iloc[i-3]\n",
    "        \n",
    "    df_dados = df_dados.drop(indices_para_remover, axis=0).reset_index(drop=True)\n",
    "    df_dados.dropna(inplace=True)\n",
    "\n",
    "    df_dados['Var Close Thursday Close Monday %'] = ((df_dados['Close Thursday'] / df_dados['Close']) - 1) * 100\n",
    "    df_dados['Trade Aconteceu Bol'] = (df_dados['Close Thursday'] >= df_dados['Low Friday']).astype(int)\n",
    "\n",
    "    arquivo_salvar = path_Data_ODS_Acoes_Estrategia002_Diario + '/' + os.path.basename(path_arquivo)\n",
    "\n",
    "    aux.write_DataFrame_csv(df_dados, arquivo_salvar)   \n",
    "\n",
    "    #Salvar Consolidado\n",
    "    df_dados_periodo = df_dados.copy()\n",
    "    df_dados_periodo = df_dados_periodo[df_dados_periodo['Trade Aconteceu Bol'] == 1]\n",
    "    \n",
    "    df_dados100 = df_dados_periodo.tail(100)        \n",
    "    soma_lp100 = df_dados100['Var Close Thursday Close Monday %'].sum()    \n",
    "    qtde_trades_lp100_total = df_dados100.count()\n",
    "    qtde_trades_lp100_positivos = (df_dados100['Var Close Thursday Close Monday %'] > 0).sum()\n",
    "    qtde_trades_lp100_negativos = (df_dados100['Var Close Thursday Close Monday %'] < 0).sum()\n",
    "\n",
    "    df_dados50 = df_dados_periodo.tail(50)\n",
    "    soma_lp50 = df_dados50['Var Close Thursday Close Monday %'].sum()    \n",
    "    qtde_trades_lp50_total = df_dados50.count()\n",
    "    qtde_trades_lp50_positivos = (df_dados50['Var Close Thursday Close Monday %'] > 0).sum()\n",
    "    qtde_trades_lp50_negativos = (df_dados50['Var Close Thursday Close Monday %'] < 0).sum()\n",
    "\n",
    "    df_dados20 = df_dados_periodo.tail(20)    \n",
    "    soma_lp20_total = df_dados20['Var Close Thursday Close Monday %'].sum()\n",
    "    qtde_trades_lp20_total = df_dados20.count()        \n",
    "    qtde_trades_lp20_positivos = (df_dados20['Var Close Thursday Close Monday %'] > 0).sum()\n",
    "    qtde_trades_lp20_negativos = (df_dados20['Var Close Thursday Close Monday %'] < 0).sum()\n",
    "\n",
    "    df_dados1 = df_dados_periodo.tail(1)\n",
    "    valor_entrada_nova = df_dados1['Close Thursday'].values\n",
    "    \n",
    "    codneg = df_dados['CODNEG'].unique()[0]\n",
    "    \n",
    "    dados_acoes.append({'CODNEG': codneg,\n",
    "                             'Valor Entrada Nova': valor_entrada_nova,                             \n",
    "                             #'Lucro/Prejuizo % - Min': df_dados['Lucro/Prejuizo %'].min(),\n",
    "                             #'Lucro/Prejuizo % - Max': df_dados['Lucro/Prejuizo %'].max(),\n",
    "                             #'Lucro/Prejuizo % - Avg': df_dados['Lucro/Prejuizo %'].mean(),\n",
    "                             #'L/P Valor - Min': df_dados['L/P Valor'].min(),\n",
    "                             #'L/P Valor - Max': df_dados['L/P Valor'].max(),\n",
    "                             #'L/P Valor - Avg': df_dados['L/P Valor'].mean(),\n",
    "                             'L/P Total 20d': soma_lp20_total,                             \n",
    "                             'L/P Count 20d': qtde_trades_lp20_total,\n",
    "                             'L/P Count 20d positivos': qtde_trades_lp20_positivos,\n",
    "                             'L/P Count 20d negativos': qtde_trades_lp20_negativos,\n",
    "                             'L/P Total 50d': soma_lp50,\n",
    "                             'L/P Count 50d': qtde_trades_lp50_total,\n",
    "                             'L/P Count 50d positivos': qtde_trades_lp50_positivos,\n",
    "                             'L/P Count 50d negativos': qtde_trades_lp50_negativos,\n",
    "                             'L/P Total 100d': soma_lp100,\n",
    "                             'L/P Count 100d': qtde_trades_lp100_total,\n",
    "                             'L/P Count 100d positivos': qtde_trades_lp100_positivos,\n",
    "                             'L/P Count 100d negativos': qtde_trades_lp100_negativos,                                                          \n",
    "                        })    \n",
    "    \n",
    "    logging.info(f\"Dados de {os.path.basename(path_arquivo)} finalizados.\")    \n",
    "\n",
    "def processar_ODS_Estrategia002_Main():\n",
    "\n",
    "    criar_pasta(path_Data_ODS_Acoes_Estrategia002_Diario)\n",
    "\n",
    "    arquivos_Diario = [(os.path.join(path_Data_STG_Acoes_Diario, f)) \n",
    "                for f in os.listdir(path_Data_STG_Acoes_Diario) if os.path.isfile(os.path.join(path_Data_STG_Acoes_Diario, f))]\n",
    "\n",
    "    threads = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        futures = [executor.submit(processar_ODS_Estrategia002, arquivo) for arquivo in arquivos_Diario]\n",
    "\n",
    "        # Aguardar todas as threads terminarem\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Captura exceções das threads, se houver\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao baixar dados da ação: {e}\")\n",
    "\n",
    "    df_acoes_consolidada = pd.DataFrame(dados_acoes)\n",
    "    \n",
    "    criar_pasta(path_Data_DM)\n",
    "\n",
    "    #Gerar arquivo consolidado\n",
    "    aux.write_DataFrame_csv(df_acoes_consolidada, path_Data_DM_Acoes_Estrategia002_Diario_Consolidado)   \n",
    "\n",
    "    logging.info(f\"Processamento finalizados.\")    \n",
    "#********************************************************************************************************\n",
    "# ESTRATEGIA 002 - FIM\n",
    "#********************************************************************************************************\n",
    "\n",
    "\n",
    "### Chamadas\n",
    "def baixar_Intraday():\n",
    "    criar_pasta(path_Data_STG_Acoes_Intraday)\n",
    "\n",
    "    threads = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        futures = [executor.submit(baixar_dados_acao, acao, path_Data_STG_Acoes_Intraday, '60m') for acao in acoes]\n",
    "\n",
    "        # Aguardar todas as threads terminarem\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Captura exceções das threads, se houver\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao baixar dados da ação: {e}\")\n",
    "\n",
    "\n",
    "def baixar_Diario():\n",
    "    criar_pasta(path_Data_STG_Acoes_Diario)\n",
    "\n",
    "    threads = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        futures = [executor.submit(baixar_dados_acao, acao, path_Data_STG_Acoes_Diario, '1d') for acao in acoes]\n",
    "\n",
    "        # Aguardar todas as threads terminarem\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Captura exceções das threads, se houver\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao baixar dados da ação: {e}\")\n",
    "    \n",
    "\n",
    "    \n",
    "def baixar_Tudo():        \n",
    "    \n",
    "    #Montar codigos\n",
    "    df_codnegs = aux.read_Dataframe_csv(path_Data_STG_Controle)\n",
    "\n",
    "    for i in df_codnegs['CODNEG'].values:\n",
    "        acoes.append(i)\n",
    "\n",
    "    baixar_Intraday()\n",
    "    \n",
    "    baixar_Diario()\n",
    "\n",
    "    logging.info('Download de todas as ações completo.')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6f407d2-d9e7-423f-a9be-fe8556f085d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 19:16:27,789 - INFO - Dados de BBSE3.SA.csv finalizados.\n"
     ]
    }
   ],
   "source": [
    "dados_acoes = []\n",
    "\n",
    "path_arquivo = path_Data_STG_Acoes_Diario + '/BBSE3.SA.csv'\n",
    "\n",
    "df_dados = aux.read_Dataframe_csv(path_arquivo)\n",
    "\n",
    "#Salvar Detalhe    \n",
    "df_dados['Date'] = pd.to_datetime(df_dados['Date'])\n",
    "df_dados.sort_values(by='Date', inplace=True)\n",
    "\n",
    "df_dados['WeekDay'] = df_dados['Date'].dt.strftime(\"%A\")\n",
    "\n",
    "df_dados = df_dados[df_dados['WeekDay'].isin(['Friday', 'Monday', 'Thursday', 'Wednesday'])]\n",
    "df_dados.reset_index(inplace=True)\n",
    "\n",
    "indices_para_remover = []\n",
    "for i in range(1, len(df_dados) - 1):\n",
    "    dia_atual = df_dados['WeekDay'].iloc[i]\n",
    "    dia_anterior = df_dados['WeekDay'].iloc[i - 1]    \n",
    "    dia_anterior_2 = df_dados['WeekDay'].iloc[i - 2]    \n",
    "    dia_anterior_3 = df_dados['WeekDay'].iloc[i - 3]    \n",
    "    \n",
    "    if dia_atual == 'Monday' and dia_anterior == 'Friday' and dia_anterior_2 == 'Thursday' and dia_anterior_3 == 'Wednesday':\n",
    "        df_dados.at[i, 'High Friday'] = df_dados['High'].iloc[i-1]\n",
    "        df_dados.at[i, 'Low Friday'] = df_dados['Low'].iloc[i-1]\n",
    "        df_dados.at[i, 'Close Thursday'] = df_dados['Close'].iloc[i-2]\n",
    "        df_dados.at[i, 'Close Wednesday'] = df_dados['Close'].iloc[i-3]\n",
    "    \n",
    "df_dados = df_dados.drop(indices_para_remover, axis=0).reset_index(drop=True)\n",
    "df_dados.dropna(inplace=True)\n",
    "\n",
    "df_dados['Trade Aconteceu Bol'] = (df_dados['Close Thursday'] >= df_dados['Low Friday']).astype(int)\n",
    "df_dados.loc[df_dados['Trade Aconteceu Bol'] == 1, 'Var Close Thursday Close Monday %'] = ((df_dados['Close Thursday'] / df_dados['Close']) - 1) * 100\n",
    "\n",
    "arquivo_salvar = path_Data_ODS_Acoes_Estrategia002_Diario + '/' + os.path.basename(path_arquivo)\n",
    "\n",
    "aux.write_DataFrame_csv(df_dados, arquivo_salvar)   \n",
    "\n",
    "lucro_prejuizo_minimo = df_dados['Var Close Thursday Close Monday %'].min()\n",
    "lucro_prejuizo_maximo = df_dados['Var Close Thursday Close Monday %'].max()\n",
    "lucro_prejuizo_media = df_dados['Var Close Thursday Close Monday %'].mean()\n",
    "rel_lucro_prejuizo = ((abs(lucro_prejuizo_maximo) / lucro_prejuizo_minimo) -1)*-1\n",
    "\n",
    "\n",
    "#Salvar Consolidado\n",
    "df_dados_periodo = df_dados.copy()\n",
    "\n",
    "df_dados100 = df_dados_periodo.tail(100)        \n",
    "soma_lp100 = float(df_dados100['Var Close Thursday Close Monday %'].sum())\n",
    "qtde_trades_lp100_total = int(df_dados100.loc[df_dados100['Trade Aconteceu Bol'] == 1, 'Var Close Thursday Close Monday %'].count())\n",
    "qtde_trades_lp100_positivos = int(df_dados100.loc[((df_dados100['Trade Aconteceu Bol'] == 1) & (df_dados100['Var Close Thursday Close Monday %'] > 0)), 'Var Close Thursday Close Monday %'].count())\n",
    "qtde_trades_lp100_negativos = int(df_dados100.loc[((df_dados100['Trade Aconteceu Bol'] == 1) & (df_dados100['Var Close Thursday Close Monday %'] < 0)), 'Var Close Thursday Close Monday %'].count())\n",
    "\n",
    "\n",
    "df_dados50 = df_dados_periodo.tail(50)\n",
    "soma_lp50 = float(df_dados50['Var Close Thursday Close Monday %'].sum())\n",
    "qtde_trades_lp50_total = int(df_dados50.loc[df_dados50['Trade Aconteceu Bol'] == 1, 'Var Close Thursday Close Monday %'].count())\n",
    "qtde_trades_lp50_positivos = int(df_dados50.loc[((df_dados50['Trade Aconteceu Bol'] == 1) & (df_dados50['Var Close Thursday Close Monday %'] > 0)), 'Var Close Thursday Close Monday %'].count())\n",
    "qtde_trades_lp50_negativos = int(df_dados50.loc[((df_dados50['Trade Aconteceu Bol'] == 1) & (df_dados50['Var Close Thursday Close Monday %'] < 0)), 'Var Close Thursday Close Monday %'].count())\n",
    "\n",
    "df_dados20 = df_dados_periodo.tail(20)    \n",
    "soma_lp20 = float(df_dados50['Var Close Thursday Close Monday %'].sum())\n",
    "qtde_trades_lp20_total = int(df_dados20.loc[df_dados20['Trade Aconteceu Bol'] == 1, 'Var Close Thursday Close Monday %'].count())\n",
    "qtde_trades_lp20_positivos = int(df_dados20.loc[((df_dados20['Trade Aconteceu Bol'] == 1) & (df_dados20['Var Close Thursday Close Monday %'] > 0)), 'Var Close Thursday Close Monday %'].count())\n",
    "qtde_trades_lp20_negativos = int(df_dados20.loc[((df_dados20['Trade Aconteceu Bol'] == 1) & (df_dados20['Var Close Thursday Close Monday %'] < 0)), 'Var Close Thursday Close Monday %'].count())\n",
    "\n",
    "df_dados1 = df_dados_periodo.tail(1)\n",
    "valor_entrada_nova = float(df_dados1['Close Thursday'].values[0])\n",
    "\n",
    "codneg = df_dados['CODNEG'].unique()[0]\n",
    "\n",
    "\n",
    "\n",
    "dados_acoes.append({'CODNEG': codneg,\n",
    "                         'Valor Entrada Nova': valor_entrada_nova,                             \n",
    "                         'Lucro/Prejuizo % - Min': df_dados['Var Close Thursday Close Monday %'].min(),\n",
    "                         'Lucro/Prejuizo % - Max': df_dados['Var Close Thursday Close Monday %'].max(),\n",
    "                         'Lucro/Prejuizo % - Avg': df_dados['Var Close Thursday Close Monday %'].mean(),\n",
    "                         #'L/P Valor - Min': df_dados['L/P Valor'].min(),\n",
    "                         #'L/P Valor - Max': df_dados['L/P Valor'].max(),\n",
    "                         #'L/P Valor - Avg': df_dados['L/P Valor'].mean(),\n",
    "                         'L/P Total 20d': soma_lp20_total,                             \n",
    "                         'L/P Count 20d': qtde_trades_lp20_total,\n",
    "                         'L/P Count 20d positivos': qtde_trades_lp20_positivos,\n",
    "                         'L/P Count 20d negativos': qtde_trades_lp20_negativos,\n",
    "                         'L/P Total 50d': soma_lp50,\n",
    "                         'L/P Count 50d': qtde_trades_lp50_total,\n",
    "                         'L/P Count 50d positivos': qtde_trades_lp50_positivos,\n",
    "                         'L/P Count 50d negativos': qtde_trades_lp50_negativos,\n",
    "                         'L/P Total 100d': soma_lp100,\n",
    "                         'L/P Count 100d': qtde_trades_lp100_total,\n",
    "                         'L/P Count 100d positivos': qtde_trades_lp100_positivos,\n",
    "                         'L/P Count 100d negativos': qtde_trades_lp100_negativos,                                                          \n",
    "                    })    \n",
    "\n",
    "logging.info(f\"Dados de {os.path.basename(path_arquivo)} finalizados.\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cac538a4-8df0-4bf1-9774-7a8df231b46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>CODNEG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-19 00:00:00-03:00</td>\n",
       "      <td>11.091186</td>\n",
       "      <td>11.375576</td>\n",
       "      <td>10.895669</td>\n",
       "      <td>11.375576</td>\n",
       "      <td>6700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-20 00:00:00-03:00</td>\n",
       "      <td>11.455560</td>\n",
       "      <td>11.508882</td>\n",
       "      <td>11.286703</td>\n",
       "      <td>11.446672</td>\n",
       "      <td>2700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-21 00:00:00-03:00</td>\n",
       "      <td>11.393349</td>\n",
       "      <td>11.482221</td>\n",
       "      <td>11.260042</td>\n",
       "      <td>11.446672</td>\n",
       "      <td>2600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-22 00:00:00-03:00</td>\n",
       "      <td>11.437785</td>\n",
       "      <td>11.473334</td>\n",
       "      <td>11.242268</td>\n",
       "      <td>11.331140</td>\n",
       "      <td>4300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-23 00:00:00-03:00</td>\n",
       "      <td>11.331140</td>\n",
       "      <td>11.464447</td>\n",
       "      <td>11.197832</td>\n",
       "      <td>11.251155</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2024-09-13 00:00:00-03:00</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>13.380000</td>\n",
       "      <td>12.890000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11700</td>\n",
       "      <td>0.122257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2024-09-16 00:00:00-03:00</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>13.150000</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2024-09-17 00:00:00-03:00</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2024-09-18 00:00:00-03:00</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>12.960000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>6900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2024-09-19 00:00:00-03:00</td>\n",
       "      <td>13.060000</td>\n",
       "      <td>13.190000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRSR3.SA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date       Open       High        Low      Close  \\\n",
       "0    2022-09-19 00:00:00-03:00  11.091186  11.375576  10.895669  11.375576   \n",
       "1    2022-09-20 00:00:00-03:00  11.455560  11.508882  11.286703  11.446672   \n",
       "2    2022-09-21 00:00:00-03:00  11.393349  11.482221  11.260042  11.446672   \n",
       "3    2022-09-22 00:00:00-03:00  11.437785  11.473334  11.242268  11.331140   \n",
       "4    2022-09-23 00:00:00-03:00  11.331140  11.464447  11.197832  11.251155   \n",
       "..                         ...        ...        ...        ...        ...   \n",
       "497  2024-09-13 00:00:00-03:00  13.300000  13.380000  12.890000  13.000000   \n",
       "498  2024-09-16 00:00:00-03:00  13.010000  13.200000  13.010000  13.150000   \n",
       "499  2024-09-17 00:00:00-03:00  13.250000  13.250000  12.750000  13.250000   \n",
       "500  2024-09-18 00:00:00-03:00  12.990000  13.200000  12.960000  13.050000   \n",
       "501  2024-09-19 00:00:00-03:00  13.060000  13.190000  12.910000  13.100000   \n",
       "\n",
       "     Volume  Dividends  Stock Splits    CODNEG  \n",
       "0      6700   0.000000           0.0  BRSR3.SA  \n",
       "1      2700   0.000000           0.0  BRSR3.SA  \n",
       "2      2600   0.000000           0.0  BRSR3.SA  \n",
       "3      4300   0.000000           0.0  BRSR3.SA  \n",
       "4      2500   0.000000           0.0  BRSR3.SA  \n",
       "..      ...        ...           ...       ...  \n",
       "497   11700   0.122257           0.0  BRSR3.SA  \n",
       "498    5500   0.000000           0.0  BRSR3.SA  \n",
       "499    8000   0.000000           0.0  BRSR3.SA  \n",
       "500    6900   0.000000           0.0  BRSR3.SA  \n",
       "501    5500   0.000000           0.0  BRSR3.SA  \n",
       "\n",
       "[502 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "path_arquivo = path_Data_STG_Acoes_Diario + '/BRSR3.SA.csv'\n",
    "\n",
    "df_dados = aux.read_Dataframe_csv(path_arquivo)\n",
    "\n",
    "df_dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d92751-3ff1-4f6c-ad75-0bec83a92816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f3af3-5fdb-4ca8-8ab5-80526fc50418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
